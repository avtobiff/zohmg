priority zero:
+ perfect docs.
+ make sure it's easy to get zohmg up and running.
+ make data export simpler.
+ nice-up export section of wiki page.
+ integrate js example.

docs:
+ clean docs, move back & make docs consistent and non-repeating
+ readme with correct webberface urls
+ (j) hadoop install scriptet nämns inte i docs
+ (j) peka folk till rätt fil i readme
+ (j) det nämns inte att man ska köra thrift interface
+ (j) ge usern steg för steg hur man startar hadoop
+ add apache.py to mapper examples
+ fix identity_mapper.py to yield correctly.

priority uno:
+ efter install-scriptet kan man inte starta hadoop/hbase
+ environment.py: use defaults.
+ use combiner
+ support for mapper class.
+ compress map output - mapred.compress.map.output=true
+ rename.
+ in usermapper, add timestamp to map of dimensions.
+ npe on empty mapper output.
+ in mapper, warn user if she supplies string as measurements value - or fix!
+ in mapper, warn user if she supplies int as dimensional value - or fix!
+ change projections syntax to list of dimensions. (I know what I mean)
+ zohmg/create.py: set default jars.
+ zohmg/create.py: make default dataset.yaml follow apache example.
+ think a bit more about serving static files.
+ put address and ports for servers and software in config (hbase REST et al)
+ some update step for post-setup alterations to dataset.yaml
+ add support for data sets.
+ create a source dist and a binary dist.
 - source dist, would distribute source and depend on thrift etc to build.
 - binary dist, ready to use eggs.


priority due:
+ (some day/maybe) build HBase thrift interface
+ (some day/maybe) ask user for path to Hbase.thrift and build hbase-*.egg
+ (some day/maybe) warn user when config is missing (what does this mean?)
+ (some day/maybe) can't use dash-values, can we? what to do; escape, or let
+ (some day/maybe) verify dimensions and units outputted by mapper.
+ (maybe never) support auto-installation on non-debian system.
+ (maybe never) support for installing in user-home
+ add description of what zohmg is and its long term goal (where?)
+ document how user contributed code is shipped to dumbo/hadoop.
+ sanity check for files shipped off to dumbo/hadoop.
  - check for existance.
  - especially for environment stuff (*_HOME and CLASSPATH).
+ better way of importing usermapper.
  - adding -pyfile to dumbo.core?
    * dumbo always does a local run before hadoop, can fail if file is not
      in PYTHONPATH (-file does not put files in PYTHONPATH, naturally).
    * set PYTHONPATH locally is the requirement.
  - "more careful" way of importing usermapper (think Mapper constructor).


DONE config.py breaks (predictably) when HADOOP_HOME is set.
WONTFIX remove the dimensions list from configuration? it's never used.
WONTFIX remove the units list from configuration? it's never used.
DONE> make sure all dependent eggs (paste, json, yaml, dumbo) are installed.
DONE> ImportError: No module named setuptools
DONE> ImportError: No module named hbase.ttypes
DONE> + ImportError when importing environment in zohmg.config.Environ
DONE better webberface
DONE class Environment is broken.
DONE> reducer is getting the order of the dimensions wrong => the cf is wrong.
DONE> shell script to install dependencies
DONE> server
DONE> transformers, plugin to data server
DONE> hbase and thrift eggs system-wideness to keep zohmg.utils happy.
DONE> add the eggs to site-packages/easy-install.pth (using setuptools?!)
DONE> bundle generated code and build eggs?
DONE> project creation
DONE> define exact dependencies, including patches, etc.
DONE> in config, rename 'project_name' to 'dataset'.
DONE> creation of dist tarball
DONE> in config, rename 'project_name' to 'dataset'.
DONE> sanity check of environment.
DONE> sanity check configuration.
DONE> darling: remove grat. prints.
WONTFIX> add lfm.data.parse egg.

examples:
 js-or-what:
  + serve html&js - maybe with paste.fileapp? => http://pythonpaste.org/modules/fileapp.html
  + cache JSON and CHARTS.
  + connect metadata to select-dropdowns.
