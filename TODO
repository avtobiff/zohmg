report:
+ graphs! images! examples!
+ abstract: non-buzzword; focus on problem
+ introduction: introduce time-series, data warehousing, mapreduce, bigtable
+ introduction: why is time important? we query for time, etc.
+ method:
+ implementation:
+ discussion:
+ write about related work.

priority zero:
+ make sure it's easy to get zohmg up and running.
+ verify that zohmg works with hbase-0.19.3
+ example firstapp: zohmg create zohmg-apps/firstapp ; cd zohmg-apps/firstapp
+ make data export simpler - why is this not a thrift interface anyways?
+ integrate js example. [paste.fileapp]

docs:
+ add description of what zohmg is and what its long term goals are
+ verify webberface url in README
+ mention that values are always ints, dimensions points always strings
+ describe the data model of hbase in README

priority uno:
+ nice-up export section of wiki page and docs.
DONE use combiner
+ support for mapper class.
DONE change projections syntax to list of dimensions. (I know what I mean)
+ add support for many data sets.
+ zohmg/create.py: do not try and create project if directory exists.
+ zohmg/create.py: make default dataset.yaml follow apache example.
+ zohmg/create.py: add apache.py to mapper examples.
+ zohmg/create.py: remove identity_mapper.py, instead bundle examples.

also:
+ would be nice to run zohmg mappers locally, to debug and what not.
+ clean darling prints ("HBaseIdentifierResolver", "cfq", "payload", etc)
+ generally do less work in __init__

data server:
+ proper root page.
+ http://127.0.0.1:8086/data => internal server error.

optimizations:
DONE compress map output - mapred.compress.map.output=true => no difference.
+ (maybe) in usermapper, add timestamp to map of dimensions.
+ cache JSON and CHARTS.

performance:
+ how many column families can we use?

showstoppers:
+ recreate error, fix: npe on empty mapper output
+ in mapper, warn user if she supplies string as measurements value - or fix!
+ in mapper, warn user if she supplies int as dimensional value - or fix!

priority due:
+ think a bit more about serving static files.
+ (some day/maybe) source dist, would distribute source and depend on thrift etc to build.
+ (some day/maybe) binary dist, ready to use eggs.
+ (some day/maybe) some update step for post-setup alterations to dataset.yaml
+ (some day/maybe) put address and ports for servers and software in config (hbase REST et al)
+ (some day/maybe) build HBase thrift interface
+ (some day/maybe) ask user for path to Hbase.thrift and build hbase-*.egg
+ (some day/maybe) warn user when config is missing (what does this mean?)
+ (some day/maybe) can't use dash-values, can we? what to do; escape, or let
+ (some day/maybe) verify dimensions and units outputted by mapper.
+ (maybe never) support auto-installation on non-debian system.
+ (maybe never) support for installing in user-home
+ document how user contributed code is shipped to dumbo/hadoop.
+ connect metadata to select-dropdowns.

per check these:
+ sanity check for files shipped off to dumbo/hadoop.
  - check for existance.
  - especially for environment stuff (*_HOME and CLASSPATH).
+ better way of importing usermapper:
  either adding -pyfile to dumbo.core? (dumbo always does a local run before hadoop,
  can fail if file is not in PYTHONPATH (-file does not put files in PYTHONPATH,
  naturally). set PYTHONPATH locally is the requirement.)
  or "more careful" way of importing usermapper (think Mapper constructor).

DONE perfect docs.
DONE add running example - aerodyne
DONE concepts in data warehousing: write intro, summary.
DONE concepts: is our use of 'hypercube' standard? => yes, common OLAP term.
DONE concepts: explain slice&dice clearer.
DONE efter install-scriptet kan man inte starta hadoop/hbase
DONE environment.py: use proper defaults.
DONE zohmg/create.py: set default jars.
DONE clean docs, move back & make docs consistent and non-repeating
DONE (j) hadoop install scriptet nämns inte i docs
DONE (j) peka folk till rätt fil i readme
DONE (j) det nämns inte att man ska köra thrift interface
DONE (j) ge usern steg för steg hur man startar hadoop
DONE config.py breaks (predictably) when HADOOP_HOME is set.
WONTFIX remove the dimensions list from configuration? it's never used.
WONTFIX remove the units list from configuration? it's never used.
WONTFIX> add lfm.data.parse egg.
DONE> make sure all dependent eggs (paste, json, yaml, dumbo) are installed.
DONE> ImportError: No module named setuptools
DONE> ImportError: No module named hbase.ttypes
DONE> + ImportError when importing environment in zohmg.config.Environ
DONE better webberface
DONE class Environment is broken.
DONE> reducer is getting the order of the dimensions wrong => the cf is wrong.
DONE> shell script to install dependencies
DONE> server
DONE> transformers, plugin to data server
DONE> hbase and thrift eggs system-wideness to keep zohmg.utils happy.
DONE> add the eggs to site-packages/easy-install.pth (using setuptools?!)
DONE> bundle generated code and build eggs?
DONE> project creation
DONE> define exact dependencies, including patches, etc.
DONE> in config, rename 'project_name' to 'dataset'.
DONE> creation of dist tarball
DONE> in config, rename 'project_name' to 'dataset'.
DONE> sanity check of environment.
DONE> sanity check configuration.
DONE> darling: remove grat. prints.
